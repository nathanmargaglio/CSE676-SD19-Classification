{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import scipy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my GPU has little ram, so we're just gonna use the CPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir('by_class')\n",
    "\n",
    "data_pairs = []\n",
    "for class_int, class_dir in enumerate(classes):\n",
    "    image_path = 'by_class/{}/train_{}/'.format(class_dir, class_dir)\n",
    "    image_files = os.listdir(image_path)\n",
    "    for d in [image_path + img for img in image_files]:\n",
    "        data_pairs.append((d, class_int))\n",
    "        \n",
    "x_data = np.array(data_pairs)[::,0]\n",
    "y_data = keras.utils.to_categorical(np.array(data_pairs)[::,1], len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_idx = np.arange(0, len(x_data))\n",
    "train_idx = np.random.choice(full_idx, \n",
    "                             int(len(x_data)*0.8), \n",
    "                             replace=False)\n",
    "test_idx = np.setdiff1d(full_idx, train_idx)\n",
    "\n",
    "x_train = x_data[train_idx]\n",
    "y_train = y_data[train_idx]\n",
    "x_test = x_data[test_idx]\n",
    "y_test = y_data[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f45e7f58a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f463dad7278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    im = imageio.imread(data_pairs[591000][0], pilmode='L')/255\n",
    "except TypeError as e:\n",
    "    im = scipy.misc.imread(data_pairs[591000][0], mode='L')/255\n",
    "print(data_pairs[590000][1])\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x, y, batch_size=32, iterate=False):\n",
    "    count = 0\n",
    "    while True:\n",
    "        idx = np.random.randint(0, len(x), batch_size)\n",
    "        if iterate:\n",
    "            idx = np.arange(count*batch, (count+1)*batch)\n",
    "            if idx[-1] > len(x):\n",
    "                yield np.array([]), np.array([])\n",
    "        im_files = x[idx]\n",
    "        ims = []\n",
    "        labels = y[idx]\n",
    "        \n",
    "        for i in im_files:\n",
    "            try:\n",
    "                image = imageio.imread(i, pilmode='L')/255\n",
    "            except TypeError as e:\n",
    "                image = scipy.misc.imread(i, mode='L')/255\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            ims.append(image)\n",
    "\n",
    "        yield np.array(ims), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45e7f0d0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick test\n",
    "for gen, label in batch_generator(x_train, y_train):\n",
    "    for im, l in zip(gen, label):\n",
    "        print(l)\n",
    "        print(np.argmax(l))\n",
    "        plt.imshow(im.reshape(128,128))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,\n",
    "                 data_format=\"channels_first\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "adadelta = Adadelta(lr=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 32s 4s/step - loss: 3.7911 - categorical_accuracy: 0.1406 - val_loss: 3.5062 - val_categorical_accuracy: 0.1523\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 31s 4s/step - loss: 3.5319 - categorical_accuracy: 0.1914 - val_loss: 3.3885 - val_categorical_accuracy: 0.2227\n",
      "Epoch 3/1000\n",
      "7/8 [=========================>....] - ETA: 2s - loss: 3.6012 - categorical_accuracy: 0.1250"
     ]
    }
   ],
   "source": [
    "callback_list = []\n",
    "train_name = str(int(time.time()))\n",
    "if not os.path.exists('models/' + train_name):\n",
    "    os.makedirs('models/' + train_name)\n",
    "callback_list.append(EarlyStopping(monitor='val_loss', patience=100))\n",
    "callback_list.append(TensorBoard(log_dir='./logs/' + train_name))\n",
    "model_path=\"models/\" + str(int(time.time())) +\"/model_{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "callback_list.append(ModelCheckpoint(model_path, monitor='val_categorical_accuracy', period=10))\n",
    "\n",
    "train_gen = batch_generator(x_train, y_train, batch_size=32)\n",
    "test_gen = batch_generator(x_test, y_test, batch_size=32)\n",
    "\n",
    "hist = model.fit_generator(generator=train_gen,\n",
    "                    validation_data=test_gen,\n",
    "                    steps_per_epoch=8,\n",
    "                    validation_steps=8,\n",
    "                    epochs=1000,\n",
    "                    verbose=1,\n",
    "                    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hist.history)\n",
    "df.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_gen, steps=10, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test categorical accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in test_gen:\n",
    "    pred = model.predict(x)\n",
    "    for xp, l in zip(pred, y):\n",
    "        print(\"Predicition:\", np.argmax(xp))\n",
    "        print(\"Actual     :\", np.argmax(l))\n",
    "        print(\"----------------------\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gen = batch_generator(x_test, y_test, batch_size = 100)\n",
    "y_true = np.array([])\n",
    "y_pred = np.array([])\n",
    "\n",
    "for x, y in all_gen:\n",
    "    if not y_true.size:\n",
    "        y_true = y_true.reshape((0, y.shape[1]))\n",
    "        y_pred = y_true.reshape((0, y.shape[1]))\n",
    "\n",
    "    y_true = np.concatenate((y_true, y))\n",
    "    \n",
    "    _y = model.predict(x)\n",
    "    y_pred = np.concatenate((y_pred, _y))\n",
    "    \n",
    "    if len(y_true) == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1))\n",
    "plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.read_csv('run_1536441301-tag-loss.csv')\n",
    "df_val_loss = pd.read_csv('run_1536441301-tag-val_loss.csv')\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Categorical Crossentropy\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='C0', label='Training Loss'),\n",
    "    mpatches.Patch(color='C1', label='Validation Loss')\n",
    "])\n",
    "\n",
    "plt.plot(df_loss.Step, df_loss.Value)\n",
    "plt.plot(df_val_loss.Step, df_val_loss.Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.read_csv('run_1536441301-tag-categorical_accuracy.csv')\n",
    "df_val_loss = pd.read_csv('run_1536441301-tag-val_categorical_accuracy.csv')\n",
    "\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Categorical Accuracy\")\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='C0', label='Training Accuracy'),\n",
    "    mpatches.Patch(color='C1', label='Validation Accuracy')\n",
    "])\n",
    "\n",
    "plt.plot(df_loss.Step, df_loss.Value)\n",
    "plt.plot(df_val_loss.Step, df_val_loss.Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
